swetwd("D:/새 폴더/1025 1차시_설치,자료형,기본구조,워드클라우드/")
swtwd("D:/새 폴더/1025 1차시_설치,자료형,기본구조,워드클라우드/")
setwd("D:/새 폴더/1025 1차시_설치,자료형,기본구조,워드클라우드/")
input1 <- readLines("president.txt")
input1 <- readLines("president.txt")
list.files()
input1
library(RColorBrewer)
library(wordcloud)
install.packages("KoNLP")
library("KoNLP")
library(KoNLP)
library(KoNLP)
library("KoNLP")
library(KoNLP)
library(wordcloud)
library(RColorBrewer)
useSejongDic
useSejongDic()
##### 명사추출
data <- sapply(input1, extractNoun)
View(data)
View(data)
View(data)
##### 명사추출
data <- sapply(input1, extractNoun, USE.NAMES = F) #input1 벡터를 extractNoun 함수에 적용
View(data)
View(data)
data
##### 명사추출
data <- sapply(input1, extractNoun) #input1 벡터를 extractNoun 함수에 적용
data
USE.NAMES = F
USE.NAMES = F
data
#USE.NAMES = F 옵션은 원본을 없애준다.
data_unlist <- unlilst(data)
data_unlist
#USE.NAMES = F 옵션은 원본을 없애준다.
data_unlist <- unlist(data)
data_unlist
data_unlist
#USE.NAMES = F 옵션은 원본을 없애준다.
data
##### 명사추출
data <- sapply(input1, extractNoun, USE.NAMES = F) #input1 벡터를 extractNoun 함수에 적용
#USE.NAMES = F 옵션은 원본을 없애준다.
data
data_unlist <- unlist(data)
data_unlist
word_count <- table(data_unlist)
word_count
head(sort(wordcount, decreasing = T), 10)
head(sort(word_count, decreasing = T), 10)
pal <- brewer.pal(9, "YlOrRd")
wordcloud(names(word_count), word_count, col = pal)
wordcloud(names(word_count), word_count, col = pal, random.order = F)
pal <- brewer.pal(9, "set")
wordcloud(names(word_count), word_count, col = pal, random.order = F)
pal <- brewer.pal(9, "set")
wordcloud(names(word_count), word_count, col = pal, random.order = F)
palette()
brewer.pal.info
pal <- brewer.pal(9, "Set1")
wordcloud(names(word_count), word_count, col = pal, random.order = F)
pal <- brewer.pal(9, "Set2")
wordcloud(names(word_count), word_count, col = pal, random.order = F)
brewer
brewer.list
brewer.pal()
??brewer
display.brewer.all
display.brewer.all()
pal <- brewer.pal(9, "Pastel2")
wordcloud(names(word_count), word_count, col = pal, ran, random.order = F)
wordcloud(names(word_count), word_count, col = pal, ran, random.order = F)
wordcloud(names(word_count), word_count, col = pal, random.order = F)
display.brewer.all()
display.brewer.all()
pal <- brewer.pal(9, "Set3")
library(KoNLP)
library(wordcloud)
library(RColorBrewer)
setwd("D:/새 폴더/1025 1차시_설치,자료형,기본구조,워드클라우드")
list.files()
review = readLines("review.txt")
useSejongDic()
data <- sapply(review, extractNoun, USE.NAMES = F)
data
data_unlist <- unlist(data)
data_unlist
wordcount <- table(data_unlist)
wordcount
head(sort(wordcount, decreasing = T), 10)
pal = brewer.pal(9,"Set3")
wordcloud(names(wordcount),wordcount, col = pal)
head(sort(wordcount, decreasing = T), 50)
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcloud(names(wordcount_top30),wordcount, col = pal, random.order=F)
wordcount_top30 <- head(sort(wordcount, decreasing = T),3 0)
wordcount_top30 <- head(sort(wordcount, decreasing = T), 30)
wordcount_top30
wordcloud(names(wordcount_top30),wordcount, col = pal, random.order=F)
wordcount
wordcount_top30
wordcloud(names(wordcount_top30),wordcount, col = pal, random.order=F)
wordcloud(names(wordcount_top30),wordcount, col = pal, random.order=F, scale(5,1))
#사전에 단어 추가,
mergerUserDic(Data.frame("존잼","ncn"))
#사전에 단어 추가,
mergerUserDic(Data.frame(c("존잼"),c("ncn")))
#사전에 단어 추가,
mergeUserDic(Data.frame(c("존잼"),c("ncn")))
#사전에 단어 추가,
mergeUserDic(data.frame(c("존잼"),c("ncn")))
add_dic <- readLines("word_list.txt")
add_dic
for (i in 1:length(add_dic)){
mergeUserDic(data.frame(add_dic[i], c("ncn")))
}
wordcount <- table(data_unlist)
wordcount
wordcount_top30 <- head(sort(wordcount, decreasing = T), 30)
wordcount_top30
pal = brewer.pal(9,"Set3")
wordcloud(names(wordcount_top30),wordcount, col = pal, random.order=F)
wordcount_top30 <- head(sort(wordcount, decreasing = T),10)
wordcount_top30
pal = brewer.pal(9,"Set3")
wordcloud(names(wordcount_top30),wordcount, col = pal, random.order=F)
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F)
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
pal = brewer.pal(9,"Set3")
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F)
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
###사전에 단어를 추가한 뒤 sapply 를 통해 명사를 추출한다.
data <- sapply(review, extractNoun, USE.NAMES = F)
data
data_unlist <- unlist(data)
data_unlist
wordcount <- table(data_unlist)
wordcount
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
pal = brewer.pal(9,"Set3")
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F)
View(data)
View(data)
wordcount_top30
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F, scale = c(3,1))
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F, scale = c(5,1))
pal = brewer.pal(9,"Set2")
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F, scale = c(5,1))
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F, scale = c(5,1))
###원하지 않는 단어를 삭제하기
data_unlist = gsub("영화","",data_unlist)
wordcount <- table(data_unlist)
wordcount
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
review_unlist <- Filter(function(x){nchar() >= 2}, review_unlist)
review_unlist <- Filter(function(x){nchar() >= 2}, data_unlist)
review_unlist <- Filter(function(x){nchar() >= 2}, data_unlist)
review_unlist <- Filter(function(x){nchar(x) >= 2}, data_unlist)
wordcount <- table(data_unlist)
wordcount
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
###원하지 않는 단어를 삭제하기
data_unlist = gsub("영화","",data_unlist)
data_unlist <- Filter(function(x){nchar(x) >= 2}, data_unlist)
wordcount <- table(data_unlist)
wordcount
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
pal = brewer.pal(9,"Set2")
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F, scale = c(5,1))
display.brewer.all()
pal = brewer.pal(9,"Spectral")
display.brewer.all()
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F, scale = c(5,1))
data_unlist = gsub("^ㅋ","",data_unlist)
data_unlist = gsub("^ㅎ","",data_unlist)
###글자수가 1개 이하인 문자는 삭제하기
data_unlist <- Filter(function(x){nchar(x) >= 2}, data_unlist)
wordcount <- table(data_unlist)
wordcount
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
pal = brewer.pal(9,"Spectral")
display.brewer.all()
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F, scale = c(5,1))
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F, scale = c(3,1))
###원하지 않는 단어를 삭제하기
data_unlist = gsub("영화","",data_unlist)
data_unlist = gsub("^ㅋ","",data_unlist)
data_unlist = gsub("^ㅎ","",data_unlist)
###글자수가 1개 이하인 문자는 삭제하기
data_unlist <- Filter(function(x){nchar(x) >= 2}, data_unlist)
wordcount <- table(data_unlist)
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
data_unlist <- unlist(data)
data_unlist
###원하지 않는 단어를 삭제하기
data_unlist = gsub("영화","",data_unlist)
data_unlist = gsub("^ㅋ","",data_unlist)
data_unlist = gsub("^ㅎ","",data_unlist)
wordcount <- table(data_unlist)
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
display.brewer.all()
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F, scale = c(3,1))
wordcount_top30
###글자수가 1개 이하인 문자는 삭제하기
data_unlist <- Filter(function(x){nchar(x) >= 2}, data_unlist)
wordcount_top30
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
wordcount <- table(data_unlist)
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
wordcount_top30
wordcount_top30 = gsub("^z","",wordcount_top30)
wordcount_top30
wordcount_top30
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
review = readLines("review.txt")
useSejongDic()
###사전에 단어 추가, 텍스트파일에 단어 리스트 저장하여 for 문으로 읽어오
mergeUserDic(data.frame(c("존잼"),c("ncn")))
add_dic <- readLines("word_list.txt")
for (i in 1:length(add_dic)){
mergeUserDic(data.frame(add_dic[i], c("ncn")))
}
###사전에 단어를 추가한 뒤 sapply 를 통해 명사를 추출한다.
data <- sapply(review, extractNoun, USE.NAMES = F)
data
data_unlist <- unlist(data)
data_unlist
###원하지 않는 단어를 삭제하기
data_unlist = gsub("영화","",data_unlist)
data_unlist = gsub("^ㅋ","",data_unlist)
data_unlist = gsub("^ㅎ","",data_unlist)
data_unlist
###글자수가 1개 이하인 문자는 삭제하기
data_unlist <- Filter(function(x){nchar(x) >= 2}, data_unlist)
data_unlist
data_unlist = gsub("^ㅎ","",data_unlist)
data_unlist
data_unlist = gsub("^ㅎ","ㅎ",data_unlist)
data_unlist
data_unlist = gsub("^ㅋ","ㅋ",data_unlist)
data_unlist
add_dic <- readLines("word_list.txt")
add_dic
for (i in 1:length(add_dic)){
mergeUserDic(data.frame(add_dic[i], c("ncn")))
}
###사전에 단어를 추가한 뒤 sapply 를 통해 명사를 추출한다.
data <- sapply(review, extractNoun, USE.NAMES = F)
data
data_unlist <- unlist(data)
data_unlist
###원하지 않는 단어를 삭제하기
data_unlist = gsub("영화","",data_unlist)
data_unlist = gsub("^ㅋ","",data_unlist)
data_unlist = gsub("^ㅎ","",data_unlist)
###글자수가 1개 이하인 문자는 삭제하기
data_unlist <- Filter(function(x){nchar(x) >= 2}, data_unlist)
data_unlist
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
wordcount_top30[35]
class(wordcount_top30)
wordcount_top30-wordcount_top30[35]
wordcount_top30<-wordcount_top30[35]
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30<-wordcount_top30[-35]
wordcount_top30
wordcount_top30<-wordcount_top30[-39]
wordcount_top30
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F, scale = c(3,1))
wordcount_top30[10]
wordcount_top30[10,2]
wordcount_top30[10]
wordcount_top30[10][2]
wordcount_top30[10][1
wordcount_top30[10][1]
wordcount_top30[10]
data_unlist = gsub("하게","",data_unlist)
data_unlist = gsub("해서","",data_unlist)
data_unlist
###글자수가 1개 이하인 문자는 삭제하기
data_unlist <- Filter(function(x){nchar(x) >= 2}, data_unlist)
wordcount <- table(data_unlist)
wordcount
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30[10]
#지정 열을 없애주기(ㅋ, ㅎ같은 것들이 포함되어있었다.)
wordcount_top30<-wordcount_top30[-35]
wordcount_top30<-wordcount_top30[-39]
pal = brewer.pal(9,"Spectral")
display.brewer.all()
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F, scale = c(3,1))
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
###글자수가 1개 이하인 문자는 삭제하기
data_unlist <- Filter(function(x){nchar(x) >= 2}, data_unlist)
wordcount <- table(data_unlist)
wordcount
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
#지정 열을 없애주기(ㅋ, ㅎ같은 것들이 포함되어있었다.)
wordcount_top30<-wordcount_top30[-33]
wordcount_top30<-wordcount_top30[-38]
wordcount_top30[10]
wordcount_top30
###글자수가 1개 이하인 문자는 삭제하기
data_unlist <- Filter(function(x){nchar(x) >= 2}, data_unlist)
wordcount <- table(data_unlist)
wordcount
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
wordcount_top30
#지정 열을 없애주기(ㅋ, ㅎ같은 것들이 포함되어있었다.)
wordcount_top30<-wordcount_top30[-33]
wordcount_top30
wordcount_top30<-wordcount_top30[-38]
wordcount_top30[10]
wordcount_top30
wordcount_top30<-wordcount_top30[-37]
wordcount_top30
###글자수가 1개 이하인 문자는 삭제하기
data_unlist <- Filter(function(x){nchar(x) >= 2}, data_unlist)
wordcount <- table(data_unlist)
wordcount
wordcount_top30 <- head(sort(wordcount, decreasing = T), 50)
#지정 열을 없애주기(ㅋ, ㅎ같은 것들이 포함되어있었다.)
wordcount_top30<-wordcount_top30[-33]
wordcount_top30
wordcount_top30<-wordcount_top30[-37]
wordcount_top30
wordcloud(names(wordcount_top30),wordcount_top30, col = pal, random.order=F, scale = c(3,1))
??wordcloud
setwd("D:/Rvisualize/TextMining_Exam01_President")
list.files()
txt <- readLines("kakaotalk.txt")
txt
txt
txt <- readLines("kakaotalk.txt")
txt
setwd("D:/Rvisualize/TextMining_Exam01_President")
list.files()
txt <- readLines("kakaotalk.txt")
txt
txt <- readLines("kakaotalk.txt")
txt
txt <- readLines("kakaotalk.txt")
txt
??readLines
txt <- readLines("kakaotalk.txt", encoding = "auto")
??readLines
txt
txt <- readLines("kakaotalk.txt", encoding = "UTF-8")
txt
library(KoNLP)
library(RColorBrewer)
library(wordcloud)
useSejongDic()
data <- sapply(txt, extractNoun, USE.NAMES = F)
data
data_unlist = unlist(data)
data_unlist
wordcount = table(data_unlist)
wordcount
head(sort(wordcount, decreasing = T), 10)
head(sort(wordcount, decreasing = T), 50)
class(data)
class(data_unlist)
head(sort(wordcount, decreasing = T), 100)
data_unlist <- Filter(function(x){nchar(x) >= 2}, data_unlist)
wordcount = table(data_unlist)
wordcount
head(sort(wordcount, decreasing = T), 100)
head(sort(wordcount, decreasing = T), 200)
final <- head(sort(wordcount, decreasing = T), 200)
final
final <- final[-1]
final
final <- final[-1]
final
final <- final[-1]
final <- final[-1]
final
head(final,30)
final <- final[-2]
head(final,30)
final <- final[-3]
head(final,30)
final <- final[-2]
head(final,30)
final <- final[-2:3]
final <- final[-c(2,3)]
head(final,30)
final <- final[-c(3:5)]
head(final,30)
final <- final[-c(5:6)]
head(final,30)
final <- final[-c(7:14)]
head(final,30)
final <- final[-c(6)]
head(final,30)
final <- gsub("[한솥","한솥",final)
final <- gsub("\[한솥","한솥",final)
final <- gsub("/[한솥","한솥",final)
head(final,30)
final <- final[-c(7:9)]
head(final,30)
wordcloud(names(final),final)
display.brewer.all()
pal = brewer.pal(9,"Paired")
wordcloud(names(final),final, random.order = F, col = pal)
library(wordcloud)
library(RColorBrewer)
library(KoNLP)
setwd("D:/새 폴더/1025 1차시_설치,자료형,기본구조,워드클라우드")
list.files()
review = readLines("review.txt")
useSejongDic()
###사전에 단어 추가, 텍스트파일에 단어 리스트 저장하여 for 문으로 읽어오
mergeUserDic(data.frame(c("존잼"),c("ncn")))
v1 <- c(150,130,160,100,180) #사과판매량
v2 <- c(120,150,100,80,20)  #키위판매량
v3 <- c(80,20,30,10,50) #포도판매량
plot(v1, type = "o", lwd="2", col = "#ee7777", main="Fruits", ylim=c(0,300), axis=vday, xlab ="DAY", ylab = "PRICE", axes=F)
axis(2, ylim=c(0,200))
axis(1, at = 1:5, lab = vday)
lines(v2, type="o", lwd="2", col = "#77ee77")
lines(v3, type="o", lwd="2", col = "#7777ee")
legend(3, 300, c("딸기","키위","포도"), col = c("#ee7777","#77ee77","#7777ee"), lty=c(1,2,3), lwd=c(5,4,3))
legend(3, 300, c("딸기","키위","포도"), col = c("#ee7777","#77ee77","#7777ee"), lty=c(1,2,3), lwd=c(5,4,3))
legend(3, 300, c("딸기","키위","포도"), col = c("#ee7777","#77ee77","#7777ee"), lty=c(1,2,3), lwd=c(5,4,3))
v1 <- c(150,130,160,100,180) #사과판매량
v2 <- c(120,150,100,80,20)  #키위판매량
v3 <- c(80,20,30,10,50) #포도판매량
plot(v1, type = "o", lwd="2", col = "#ee7777", main="Fruits", ylim=c(0,300), axis=vday, xlab ="DAY", ylab = "PRICE", axes=F)
axis(2, ylim=c(0,200))
axis(1, at = 1:5, lab = vday)
lines(v2, type="o", lwd="2", col = "#77ee77")
lines(v3, type="o", lwd="2", col = "#7777ee")
legend(3, 300, c("딸기","키위","포도"), col = c("#ee7777","#77ee77","#7777ee"), lty=c(1,2,3), lwd=c(5,4,3))
